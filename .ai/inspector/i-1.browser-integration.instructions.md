# Browser Integration Testing Instructions

## Purpose

Validate backend API integration from real browser perspective using browser developer tools inspection. This phase bridges implementation (Builder) and formal testing (Craftsman) by catching integration issues early.

## Role Context

This is an **optional phase** in the AIDD workflow, positioned between Builder and Craftsman:

```
Architect → Builder → [Inspector] → Craftsman → Deploy
```

## When to Use

Use the Inspector phase when:
- Implementing authentication/authorization endpoints
- Working on APIs consumed by frontend applications
- Debugging CORS, headers, or content-type issues
- Validating API response formats and error messages
- Measuring API performance from client perspective
- Before final deployment to production

Skip this phase when:
- Working on pure backend logic without HTTP exposure
- Internal microservices not accessed by browsers
- Command-line tools or background jobs

## Input

- Implemented API endpoints (from Builder phase)
- API documentation or endpoint list
- Expected request/response formats
- Authentication requirements

## Process

### 1. Setup Inspection Environment

Connect AI to browser developer tools using available protocols:
- Browser DevTools Protocol (Chrome, Edge, Firefox)
- Remote debugging capabilities
- Network inspection tools
- Console monitoring

### 2. Prepare Test Scenarios

Create minimal test page or use API testing tools:
- Simple HTML page with JavaScript fetch calls
- API testing tools (Postman, Insomnia, HTTP clients)
- Automated browser scripts
- Manual browser testing

### 3. Inspection Focus Areas

#### Network Tab
- HTTP status codes
- Request/response headers
- Request/response bodies
- Response times
- Error responses
- CORS preflight requests

#### Console Tab
- JavaScript errors
- Network errors
- Warning messages
- Authentication failures

#### Application/Storage Tab
- Token storage (localStorage, sessionStorage, cookies)
- Token format and expiration
- Secure attributes on cookies

#### Performance
- API response times
- Payload sizes
- Bottlenecks
- Resource loading

### 4. Validation Checklist

For each API endpoint, verify:
- [ ] Returns correct HTTP status codes
- [ ] Response format matches documentation
- [ ] Error responses are informative
- [ ] CORS headers configured correctly
- [ ] Authentication headers accepted
- [ ] Content-Type headers correct
- [ ] No console errors on success paths
- [ ] Performance within acceptable range

### 5. Issue Documentation

For each issue found, document:
- **Endpoint**: API path and method
- **Issue Type**: CORS, Auth, Format, Performance, Error
- **Current Behavior**: What happens now
- **Expected Behavior**: What should happen
- **Browser Evidence**: Console messages, network tab details
- **Suggested Fix**: Backend changes needed

## Output Deliverables

- `docs/features/{feature-slug}/integration-issues.md`: List of integration problems found
- Updated implementation plans with fixes
- Performance baseline metrics
- Integration validation report

## Quality Gates

Before transitioning from Inspector to Craftsman:
- [ ] All critical integration issues resolved
- [ ] CORS configuration validated
- [ ] Authentication flow works end-to-end
- [ ] Error responses are client-friendly
- [ ] No JavaScript console errors on happy paths
- [ ] Performance meets basic thresholds

## Tool Requirements

The AI should have access to:
- Browser DevTools inspection capabilities
- Ability to load test pages or make HTTP requests
- Console output monitoring
- Network request/response inspection
- Screenshot capture (optional)

## Best Practices

1. **Test with Real Browsers**: Use actual browser environments, not just API tools
2. **Focus on Integration**: Look for issues at the HTTP boundary, not internal logic
3. **Document Evidence**: Include specific error messages and network details
4. **Prioritize Issues**: Critical (blocks functionality) vs. Minor (usability)
5. **Suggest Fixes**: Include backend code changes to resolve issues
6. **Measure Performance**: Establish baseline metrics for future comparison

## Example Workflow

1. AI connects to browser DevTools
2. AI loads test page that calls `/api/auth/login/`
3. AI inspects network request:
   - Sees 401 with CORS error
   - Identifies missing `Access-Control-Allow-Origin` header
4. AI documents issue with evidence
5. AI suggests backend fix: Add CORS middleware configuration
6. AI verifies fix after implementation
7. AI moves to next endpoint

## Notes

- This phase complements, not replaces, formal testing (Craftsman phase)
- Focus on observable HTTP behavior, not internal implementation
- Use this phase to improve API usability from client perspective
- Integration issues found here should inform test cases in Craftsman phase
